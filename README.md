# ğŸ§  Agentic RAG Chatbot for Multi-Format Document QA using MCP

A lightweight, agent-based Retrieval-Augmented Generation (RAG) chatbot designed to answer user questions from uploaded documents of various formats â€” powered by **Model Context Protocol (MCP)** and **Streamlit**.
Supports **PDF, DOCX, PPTX, CSV, TXT, Markdown** files. Built with modular agents and vector search using **ChromaDB**.

---

## ğŸš€ Features

âœ… Upload & parse diverse document formats
âœ… Agent-based design: Ingestion, Retrieval, LLM Response
âœ… MCP-style structured message passing (in-memory)
âœ… Uses Open Source LLMs via **Groq**
âœ… Clean multi-turn Q\&A interface with **Streamlit**
âœ… Pluggable vector store using **ChromaDB**

---

## ğŸ“ Project Structure

```
Agentic-RAG-Chatbot/
â”‚
â”œâ”€â”€ app.py                         # Streamlit UI
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py        # Parses & preprocesses uploaded documents
â”‚   â”œâ”€â”€ retrieval_agent.py        # Handles embedding + retrieval via Chroma
â”‚   â””â”€â”€ llm_response_agent.py     # Queries the LLM using retrieved context
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ doc_parser.py             # Handles parsing for PDF, DOCX, CSV, etc.
â”‚   â””â”€â”€ vectorstore_utils.py      # Embedding & ChromaDB logic
â”‚
â”œâ”€â”€ mcp/
â”‚   â”œâ”€â”€ mcp_models.py             # Pydantic-based MCP message structure
â”‚   â””â”€â”€ mcp_queue.py              # In-memory queue for agent messaging
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/                  # Raw uploaded files
â”‚   â””â”€â”€ parsed/                   # Cleaned & extracted text chunks
â”‚
â”œâ”€â”€ chroma_data/                  # Vector store (auto-created on add)
â”‚
â”œâ”€â”€ .env                          # API keys (Groq)
â”œâ”€â”€ requirements.txt              # All Python dependencies
â””â”€â”€ README.md                     # This file
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/Agentic-RAG-Chatbot.git
cd Agentic-RAG-Chatbot
```

### 2. Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate        # On Windows: .venv\\Scripts\\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up `.env`

Create a `.env` file in the root directory with your keys:

```env
GROQ_API_KEY=your-groq-key
LLM_MODEL=llama3-8b-8192
EMBEDDING_MODEL=all-MiniLM-L6-v2
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

Open the link in your browser and:

* Upload a document
* Ask a question like â€œWhat is this report about?â€
* See LLM-generated answers with source context

---

## ğŸ’¡ How It Works

1. **User Uploads Documents** â†’ Handled by `IngestionAgent`
2. **IngestionAgent** â†’ Parses content & chunks it
3. **Chunks â†’ ChromaDB** for semantic indexing
4. **User Asks a Question** â†’ Routed via `RetrievalAgent`
5. **RetrievalAgent** â†’ Gets top-matching chunks
6. **LLMResponseAgent** â†’ Uses chunks + user question â†’ Calls LLM
7. **Final Answer** â†’ Shown in UI with full chat history

All communication follows a structured **MCP message protocol** using:

```json
{
  "sender": "RetrievalAgent",
  "receiver": "LLMResponseAgent",
  "type": "RETRIEVAL_RESULT",
  "trace_id": "abc-123",
  "payload": {
    "retrieved_context": ["chunk 1", "chunk 2"],
    "query": "What are the Q1 results?"
  }
}
```

---

## ğŸ“¦ Supported File Types

* âœ… PDF
* âœ… Word (.docx)
* âœ… PowerPoint (.pptx)
* âœ… CSV
* âœ… Plain Text (.txt)
* âœ… Markdown (.md)

---

## ğŸ§ª Sample Questions

After uploading a document, try asking:

* â€œSummarize the main points.â€
* â€œWhat is the timeline mentioned?â€
* â€œList key insights.â€
* â€œWho is responsible for delivery?â€

---

## ğŸ“¸ Demo

Hereâ€™s how the Agentic RAG Chatbot looks in action:

![image](https://github.com/user-attachments/assets/36bf8866-a650-444f-86a9-b5465f7ef1b9)

---

## ğŸ“Œ Future Improvements

* ğŸ§  LangGraph-based agent control
* ğŸ” Pub/Sub or REST-based MCP
* ğŸ§¾ Chat history saving
* ğŸ” User authentication
* ğŸ“Š Metadata-aware chunking

---

## ğŸ™Œ Credits

* Built using **Python**, **Streamlit**, **Langchain-style agents**, **ChromaDB**, **Groq**
* MCP inspired by structured agent protocols
